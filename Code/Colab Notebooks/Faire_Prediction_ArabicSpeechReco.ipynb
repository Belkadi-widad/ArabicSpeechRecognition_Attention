{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4cbgwZWWfWpp"
   },
   "source": [
    "# Faire des prédictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21862,
     "status": "ok",
     "timestamp": 1600568495653,
     "user": {
      "displayName": "Hassina Pythona",
      "photoUrl": "",
      "userId": "18252505087146594994"
     },
     "user_tz": -120
    },
    "id": "tAb77yZ9fzMG",
    "outputId": "b6ab3003-df9a-47f9-b843-8cccdda60995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 95663,
     "status": "ok",
     "timestamp": 1600568598117,
     "user": {
      "displayName": "Hassina Pythona",
      "photoUrl": "",
      "userId": "18252505087146594994"
     },
     "user_tz": -120
    },
    "id": "pafL7Li0jyXW",
    "outputId": "77af6bf0-cfb1-4160-d85a-4aa78b86e896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting soundfile\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.2)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
      "Installing collected packages: soundfile\n",
      "Successfully installed soundfile-0.10.3.post1\n",
      "Collecting tf-nightly\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/85/c4e37161c5abefd8524844042a2502f9de0ff955cc34ff7b7667907b7ad3/tf_nightly-2.4.0.dev20200919-cp36-cp36m-manylinux2010_x86_64.whl (390.6MB)\n",
      "\u001b[K     |████████████████████████████████| 390.7MB 38kB/s \n",
      "\u001b[?25hCollecting tb-nightly<3.0.0a0,>=2.4.0a0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/f2/b777a7dbf8fe691416e965eabe68d699d752637772d064ed480787926b6f/tb_nightly-2.4.0a20200919-py3-none-any.whl (10.2MB)\n",
      "\u001b[K     |████████████████████████████████| 10.2MB 40.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.7.4.3)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.35.1)\n",
      "Collecting tf-estimator-nightly\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/54/e6255de0770a055ed3b9bfc90b254deb6cece5621fcffa0d0300199927c5/tf_estimator_nightly-2.4.0.dev2020091801-py2.py3-none-any.whl (460kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 46.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.18.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.3.0)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/26/712e578c5f14e26ae3314c39a1bdc4eb2ec2f4ddc89b708cf8e0a0d20423/flatbuffers-1.12-py2.py3-none-any.whl\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.32.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.2.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.7.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.17.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (50.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.7.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.1.0)\n",
      "Installing collected packages: tb-nightly, tf-estimator-nightly, flatbuffers, tf-nightly\n",
      "Successfully installed flatbuffers-1.12 tb-nightly-2.4.0a20200919 tf-estimator-nightly-2.4.0.dev2020091801 tf-nightly-2.4.0.dev20200919\n",
      "Collecting tensorflow-gpu\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/11/763f55d3d15efd778ef24453f126e6c33635680e5a2bb346da3fab5997cb/tensorflow_gpu-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
      "\u001b[K     |████████████████████████████████| 320.4MB 52kB/s \n",
      "\u001b[?25hRequirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.32.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.35.1)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (50.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
      "Installing collected packages: tensorflow-gpu\n",
      "Successfully installed tensorflow-gpu-2.3.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/Colab Notebooks/SpeechRecognition')\n",
    "!pip install soundfile\n",
    "!pip install tf-nightly\n",
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 101277,
     "status": "ok",
     "timestamp": 1600568603765,
     "user": {
      "displayName": "Hassina Pythona",
      "photoUrl": "",
      "userId": "18252505087146594994"
     },
     "user_tz": -120
    },
    "id": "KA4MrK_Sayv5"
   },
   "outputs": [],
   "source": [
    "sys.path.append('/content/drive/My Drive/Colab Notebooks/SpeechRecognition')\n",
    "\n",
    "import tensorflow as tf\n",
    "#import Preprocess_SpeechReco as old_data\n",
    "import Preprocess_bigdataset as data \n",
    "import os \n",
    "from tensorflow.keras.models import Sequential, Model , load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import time \n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 104150,
     "status": "ok",
     "timestamp": 1600568606665,
     "user": {
      "displayName": "Hassina Pythona",
      "photoUrl": "",
      "userId": "18252505087146594994"
     },
     "user_tz": -120
    },
    "id": "La8pKfcn1_PX",
    "outputId": "1d72fcaf-626a-468d-8936-e92b6c0a148e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict index   {'@': 0, '_': 1, '\"': 2, 'w': 3, 'a': 4, 'r': 5, 'j': 6, '~': 7, 'H': 8, ' ': 9, 'A': 10, 'l': 11, 't': 12, 'q': 13, 'o': 14, 'i': 15, 'y': 16, 'u': 17, '*': 18, '>': 19, 'E': 20, 'd': 21, 'h': 22, 'm': 23, 'b': 24, '^': 25, 'D': 26, 'p': 27, 'f': 28, 'k': 29, 'S': 30, 'n': 31, '-': 32, 's': 33, 'T': 34, '<': 35, '&': 36, 'Y': 37, '$': 38, 'x': 39, 'K': 40, '|': 41, '}': 42, 'g': 43, 'z': 44, \"'\": 45, 'F': 46, 'Z': 47, 'N': 48, '.': 49, 'v': 50}\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test,dic_voca=data.getData(mfccs=True,split=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 133298,
     "status": "ok",
     "timestamp": 1600568635849,
     "user": {
      "displayName": "Hassina Pythona",
      "photoUrl": "",
      "userId": "18252505087146594994"
     },
     "user_tz": -120
    },
    "id": "hkO0jn2PBf6a",
    "outputId": "a6b0b31b-3347-4fb0-bbfb-f5fecebb9293"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict index   {'@': 0, '_': 1, '\"': 2, 'w': 3, 'a': 4, 'r': 5, 'j': 6, '~': 7, 'H': 8, ' ': 9, 'A': 10, 'l': 11, 't': 12, 'q': 13, 'o': 14, 'i': 15, 'y': 16, 'u': 17, '*': 18, '>': 19, 'E': 20, 'd': 21, 'h': 22, 'm': 23, 'b': 24, '^': 25, 'D': 26, 'p': 27, 'f': 28, 'k': 29, 'S': 30, 'n': 31, '-': 32, 's': 33, 'T': 34, '<': 35, '&': 36, 'Y': 37, '$': 38, 'x': 39, 'K': 40, '|': 41, '}': 42, 'g': 43, 'z': 44, \"'\": 45, 'F': 46, 'Z': 47, 'N': 48, '.': 49, 'v': 50}\n"
     ]
    }
   ],
   "source": [
    "x_train_no_mfcc,_,x_test_no_mfcc,_,_=data.getData(mfccs=False,split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 133267,
     "status": "ok",
     "timestamp": 1600568635853,
     "user": {
      "displayName": "Hassina Pythona",
      "photoUrl": "",
      "userId": "18252505087146594994"
     },
     "user_tz": -120
    },
    "id": "99oo24wUfnX5",
    "outputId": "59adb62b-f28e-4866-fefe-5c7747fe4573"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'#/content/drive/My Drive/Colab Notebooks/SpeechRecognition/fitted_moddels/Modele_SpeechReco_1598460579_[0.9320278167724609, 0.7420995831489563].h5\\n#/content/drive/My Drive/Colab Notebooks/SpeechRecognition/fitted_moddels/Modele_SpeechReco_1598532411_[0.3269703686237335, 0.9057465195655823].h5\\nmodel= load_model(\"/content/drive/My Drive/Colab Notebooks/SpeechRecognition/fitted_moddels/Modele_SpeechReco_1598612777_[0.3621765375137329, 0.8927567601203918].h5\", \\n                  custom_objects={\\'Melspectrogram\\':Melspectrogram,\\n                        \\'Normalization2D\\':Normalization2D})\\noutput_gre1 =beam_search(model,32,x_test[60],y_test.shape[1]-1, dic_voca)\\nprint(output_gre1)'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def beam_search(model,  k, src_input, sequence_max_len,dict_voc,mfcc):\n",
    "    # (log(1), initialize_of_zeros)\n",
    "    if mfcc: \n",
    "      src_input=np.reshape(src_input, (1,src_input.shape[0],src_input.shape[1]) )\n",
    "\n",
    "    else : \n",
    "      src_input=np.reshape(src_input, (1,src_input.shape[0]) )\n",
    "    k_beam = [(0, [float(dict_voc['@'])]*(sequence_max_len))]\n",
    "    print(k_beam)\n",
    "    \n",
    "    # l : point on target sentence to predict\n",
    "    for l in range(sequence_max_len):\n",
    "        all_k_beams = []\n",
    "        for prob, sent_predict in k_beam:\n",
    "            predicted = model.predict([src_input, np.array([sent_predict])])[0]\n",
    "            #print(predicted)\n",
    "            # top k!\n",
    "            possible_k = predicted[l].argsort()[-k:][::-1]\n",
    "            #print(possible_k)\n",
    "            # add to all possible candidates for k-beams\n",
    "            all_k_beams += [\n",
    "                (\n",
    "                    sum(np.log(predicted[i][sent_predict[i+1]]) for i in range(l)) + np.log(predicted[l][next_wid]),\n",
    "                    list(sent_predict[:l+1])+[next_wid]+[0]*(sequence_max_len-l-2)\n",
    "                )\n",
    "                for next_wid in possible_k\n",
    "            ]\n",
    "        # top k\n",
    "        k_beam = sorted(all_k_beams)[-k:]\n",
    "\n",
    "    return k_beam\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S-ivIjLaFe58"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 137243,
     "status": "ok",
     "timestamp": 1600568639901,
     "user": {
      "displayName": "Hassina Pythona",
      "photoUrl": "",
      "userId": "18252505087146594994"
     },
     "user_tz": -120
    },
    "id": "vZ4dfXvuoinm",
    "outputId": "ba7fa5c6-3ad3-4705-e5e4-20af8aa7bca3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_axis=1 passed but is ignored, str_axis is used instead.\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 264600)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 264600)    0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mel_stft (Melspectrogram)       (None, 80, 2068, 1)  1091664     reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mel_stft_norm (Normalization2D) (None, 80, 2068, 1)  0           mel_stft[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 2068, 80, 1)  0           mel_stft_norm[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 2068, 80, 10) 60          permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 2068, 80, 10) 40          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 2068, 80, 1)  51          batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2068, 80, 1)  4           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "squeeze_last_dim (Lambda)       (None, 2068, 80)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) [(None, 2068, 512),  692224      squeeze_last_dim[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoder_inputs (InputLayer)     [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) [(None, 2068, 512),  1576960     bidirectional_5[0][0]            \n",
      "                                                                 bidirectional_5[0][1]            \n",
      "                                                                 bidirectional_5[0][3]            \n",
      "                                                                 bidirectional_5[0][2]            \n",
      "                                                                 bidirectional_5[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_embedding (Embedding)   (None, 150, 100)     5000        decoder_inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_6 (TensorFlo (None, 512)          0           bidirectional_6[0][1]            \n",
      "                                                                 bidirectional_6[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_7 (TensorFlo (None, 512)          0           bidirectional_6[0][2]            \n",
      "                                                                 bidirectional_6[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_9 (CuDNNLSTM)        [(None, 150, 512), ( 1257472     decoder_embedding[0][0]          \n",
      "                                                                 tf_op_layer_concat_6[0][0]       \n",
      "                                                                 tf_op_layer_concat_7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 150, 2068)    0           cu_dnnlstm_9[0][0]               \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 150, 2068)    0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 150, 512)     0           activation[0][0]                 \n",
      "                                                                 bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_8 (TensorFlo (None, 150, 1024)    0           dot_1[0][0]                      \n",
      "                                                                 cu_dnnlstm_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 150, 128)     131200      tf_op_layer_concat_8[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 150, 50)      6450        time_distributed_4[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 4,761,125\n",
      "Trainable params: 3,669,439\n",
      "Non-trainable params: 1,091,686\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "\n",
    "\n",
    "def attent_and_generate( preprocessd_input_audio,dict_voc , OUTPUT_LENGTH):\n",
    "    seaborn.set(font=['Osaka'], font_scale=3)\n",
    "\n",
    "    preprocessd_input_audio=np.reshape(preprocessd_input_audio, (1,preprocessd_input_audio.shape[0]) )\n",
    "    print(preprocessd_input_audio[0][100])\n",
    "    START_CHAR_CODE = dict_voc['@']\n",
    "    decoder_input = np.zeros(shape=(len(preprocessd_input_audio), OUTPUT_LENGTH))\n",
    "    decoder_input[:,0] = START_CHAR_CODE\n",
    "   \n",
    "    for i in range(1, OUTPUT_LENGTH):\n",
    "        \n",
    "        #argmax donne l'indice qui a la plus grande proba !\n",
    "        output, attention=attention_model.predict([preprocessd_input_audio, decoder_input])\n",
    "        output = output.argmax(axis=2)        \n",
    "        decoder_input[:,i] = output[:,i]\n",
    "        attention_density = attention[0]\n",
    "        decoded_output = data.Decode_sentence(decoder_input[0][1:],\"DICT\",dict_voc)\n",
    "        \n",
    "    return decoder_input[:,1:], decoded_output\n",
    "\n",
    "def visualize(text,dict_voc , OUTPUT_LENGTH):\n",
    "    model= load_model(\"/content/drive/My Drive/Colab Notebooks/SpeechRecognition/fitted_moddels/Modele_SpeechReco_1598612777_[0.3621765375137329, 0.8927567601203918].h5\", \n",
    "                      custom_objects={'Melspectrogram':Melspectrogram,\n",
    "                            'Normalization2D':Normalization2D})\n",
    "    attention_layer = model.get_layer(\"tf_op_layer_concat_8\") # or model.get_layer(\"tf_op_layer_concat_8\")\n",
    "    attention_model = Model(inputs=model.inputs, outputs=model.outputs + [attention_layer.output])\n",
    "    attention_model.summary()\n",
    "    attention_density, katakana = attent_and_generate(text,dict_voc , OUTPUT_LENGTH)\n",
    "    print(\"visualize chart \" , katakana)\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(148,120))\n",
    "\n",
    "    ax = seaborn.heatmap(attention_density[:len(katakana) + 2, : len(text) + 2],\n",
    "        xticklabels=[w for w in range(0,12)],\n",
    "        yticklabels=[w for w in katakana])\n",
    "\n",
    "    ax.invert_yaxis()\n",
    "    plt.show()\n",
    "#visualize(x_train[60],dic_voca,y_train.shape[1]-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "daCwHpneh9Ev",
    "outputId": "caff3edd-b9ad-45dd-b031-0b0f028892b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(517, 13)\n",
      "[(0, [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "def predict(k, path_model , path_audio,tokenzer_train , OUTPUT_LENGTH,mfccs): \n",
    "    \n",
    "    #get in the model  \n",
    "    model= load_model(path_model, \n",
    "                  custom_objects={'Melspectrogram':Melspectrogram,\n",
    "                        'Normalization2D':Normalization2D})\n",
    "    \n",
    "    #preprocessd_input_audio=preprocess_new_audio(path_audio,mfcc=mfccs)[0]\n",
    "    preprocessd_input_audio=path_audio\n",
    "    print(preprocessd_input_audio.shape)\n",
    "    #preprocessd_input_audio=path_audio\n",
    "    ''' if k==1:\n",
    "        predictions = Greedy_search(model, preprocessd_input_audio,tokenzer_train , OUTPUT_LENGTH)'''\n",
    "  \n",
    "    predictions =beam_search(model,k,preprocessd_input_audio,OUTPUT_LENGTH, dic_voca,mfcc=mfccs)\n",
    "    print(predictions)\n",
    "        \n",
    "    return predictions\n",
    "\n",
    "def preprocess_new_audio(path_audio=\"/content/drive/My Drive/Colab Notebooks/SpeechRecognition/s8L2.wav\",max_duration=12,mfcc=False) :\n",
    "\n",
    "  audio,sr= data.rosa.load(path_audio)\n",
    "  print(sr)\n",
    "  dur_audio=data.rosa.get_duration(audio)\n",
    "  audios=[]\n",
    "\n",
    "  if dur_audio<=max_duration : \n",
    "    #si inférieur à la durée le pad \n",
    "    pad_ms=(max_duration-dur_audio) *sr\n",
    "    print(\"old duration \", dur_audio )\n",
    "    audio=np.append(audio,np.zeros(int(round(pad_ms)))) \n",
    "    data.Plot_audio(audio,sr)\n",
    "\n",
    "    if mfcc : \n",
    "        audio=data.build_mfccs([audio])[0]\n",
    "    audios.append(audio)\n",
    "  else : \n",
    "    \n",
    "    # extraire les sous audios \n",
    "    nonMuteSections =data.rosa.effects.split(audio,60)\n",
    "    for i in range(0,len(nonMuteSections)):  \n",
    "      s=audio[nonMuteSections[i][0]:nonMuteSections[i][1]]\n",
    "      if mfcc : \n",
    "        s=data.build_mfccs([s])\n",
    "      audios.append(s)  \n",
    "  return audios    \n",
    "\n",
    "\n",
    "\n",
    "#path_model=\"/content/drive/My Drive/Colab Notebooks/SpeechRecognition/fitted_moddels/Modele_SpeechReco_1598612777_[0.3621765375137329, 0.8927567601203918].h5\" \n",
    "path_model=\"/content/drive/My Drive/Colab Notebooks/SpeechRecognition/fitted_moddels/Modele_SpeechReco_1599299782_[0.3388335406780243, 0.9021098017692566].h5\"\n",
    "#path_model=\"/content/drive/My Drive/Colab Notebooks/SpeechRecognition/fitted_moddels/Modele_SpeechReco_1600302374_[0.35865363478660583, 0.896904468536377].h5\"\n",
    "#path_audio=\"/content/drive/My Drive/Colab Notebooks/SpeechRecognition/output.wav\"\n",
    "index=754   \n",
    "k=64\n",
    "predictions=predict(k ,path_model,x_test[index],None,y_test.shape[1]-1,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CaiD-FBPp6_-"
   },
   "outputs": [],
   "source": [
    "def viewPredictions(text_true=u' ' , predictions=[],k=k):\n",
    "\n",
    "  for el in range(0,k) : \n",
    "    predicted = data.Decode_sentence(predictions[el][1],\"DICT\",dic_voca)\n",
    "    proba=predictions[el][0]\n",
    "    \n",
    "    print(\" output beam :  \" ,proba,\"\\n \", predicted , ' \\n', data.Test_Transcription( predicted[1] , False ))\n",
    "\n",
    "  true =data.Decode_sentence(y_test[index],\"DICT\",dic_voca)\n",
    "  print(\" le true \", true)   \n",
    "  true =data.Test_Transcription( true[1] , False )\n",
    "  print(\" le true \", true) \n",
    "data.Plot_audio(x_train_no_mfcc[index],22050)\n",
    "viewPredictions(text_true=\"العالمية\",predictions=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OdjkZoOq0Gv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Make_predictions_speechReco_25G.ipynb",
   "provenance": [
    {
     "file_id": "1Ly0LlQjQ6BAlnuZPPyUnAsTyCYp9FtDf",
     "timestamp": 1598289225028
    },
    {
     "file_id": "1GqZu6zmCy2vMNMZqO78DDuHvwv_9vJcp",
     "timestamp": 1598120624970
    },
    {
     "file_id": "1IzPbxNFQmmSYk9s14L4YjBfUgACn9mW2",
     "timestamp": 1593978024316
    },
    {
     "file_id": "1G7NKeneJNyRtcRxLVbbF9jYtRyuTOa-R",
     "timestamp": 1592749700622
    },
    {
     "file_id": "https://github.com/satyajitghana/TSAI-DeepVision-EVA4.0/blob/master/Utils/Colab_25GBRAM_GPU.ipynb",
     "timestamp": 1592043804148
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
