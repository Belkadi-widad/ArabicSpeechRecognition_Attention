{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manter le drive \n",
    "from google.colab import drive \n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instalation des package utiles \n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/Colab Notebooks/SpeechRecognition')\n",
    "!pip install soundfile\n",
    "!pip install tf-nightly\n",
    "!pip install tensorflow-gpu\n",
    "!pip install -U tensorboard_plugin_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer les p\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "#import Preprocess_SpeechReco as data\n",
    "import Preprocess_bigdataset as data \n",
    "import kapre\n",
    "import os \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Lambda, Permute ,Conv2D,BatchNormalization\n",
    "from kapre.time_frequency import Melspectrogram\n",
    "from kapre.utils import Normalization2D\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM, CuDNNGRU\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import time \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from contextlib import redirect_stdout\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions utiles pour la construction de la structure du RDN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Cette fonction permet de charger les données à partir du drive et de les préparer pour l apprentissage \n",
    "'''\n",
    "def Load_resempaled_data(shuffle=True ,split=False,mfccs=False): \n",
    "\n",
    "  if split==True :\n",
    "    #no cross validation \n",
    "\n",
    "    x_train,y_train,x_test,y_test,dict_voc= data.getData(split=True,mfccs=mfccs)\n",
    "    training_encoder_input=x_train\n",
    "    training_decoder_output=y_train\n",
    "    training_decoder_input = np.zeros_like(training_decoder_output)\n",
    "    training_decoder_input = training_decoder_output[:,:-1]\n",
    "    voc_size=len(dict_voc)\n",
    "    output_length=training_decoder_input.shape[1]\n",
    "    input_length=training_encoder_input.shape[1]\n",
    "    #one hot incoding \n",
    "    print(training_decoder_output[:,1:])\n",
    "    training_decoder_output = np.eye(voc_size)[training_decoder_output[:,1:].astype('int')]\n",
    "    print(training_decoder_input)\n",
    "    print(training_decoder_input.shape)\n",
    "    print(training_decoder_output.shape)\n",
    "    validation_encoder_input=x_test \n",
    "    validation_decoder_output=y_test \n",
    "    print(validation_decoder_output.shape)\n",
    "    validation_decoder_input = np.zeros_like(validation_decoder_output)\n",
    "    validation_decoder_input = validation_decoder_output[:,:-1]\n",
    "    #one hot incoding \n",
    "    validation_decoder_output = np.eye(voc_size)[validation_decoder_output[:,1:].astype('int')]\n",
    "    print(validation_decoder_input.shape)\n",
    "    print(validation_decoder_output.shape)\n",
    "    \n",
    "\n",
    "    return   input_length,output_length,voc_size,training_encoder_input, training_decoder_input,training_decoder_output,validation_encoder_input, validation_decoder_input, validation_decoder_output\n",
    "  else : \n",
    "    #for cross validation \n",
    "    \n",
    "    x_train,y_train,dict_voca= data.getData(split=False,mfccs=mfccs)\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    dict_voc=dict_voca\n",
    "    training_encoder_input=x_train\n",
    "    #training_decoder_output=y_train[3083:]\n",
    "    training_decoder_output=y_train\n",
    "    training_decoder_input = np.zeros_like(training_decoder_output)\n",
    "    training_decoder_input = training_decoder_output[:,:-1]\n",
    "    voc_size=len(dict_voc)\n",
    "    output_length=training_decoder_input.shape[1]\n",
    "    input_length=training_encoder_input.shape[1]\n",
    "    #one hot incoding \n",
    "    print(training_decoder_output[:,1:])\n",
    "    training_decoder_output = np.eye(voc_size)[training_decoder_output[:,1:].astype('int')]\n",
    "    print(training_decoder_input)\n",
    "    print(training_decoder_input.shape)\n",
    "    print(training_decoder_output.shape)\n",
    "\n",
    "    return   input_length,output_length,voc_size,training_encoder_input, training_decoder_input,training_decoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the encoder \n",
    "# cette fonction permet de construire la couche qui produit les spectrogrammes de mel ( au lieu  des mfccs )\n",
    "def Build_MelSpectrogram(Parametres_layer,input_length): \n",
    "\n",
    "  mel_layer = Melspectrogram(n_dft=Parametres_layer[\"n_dft\"],\n",
    "                             n_hop=Parametres_layer[\"n_hop\"],\n",
    "                             input_shape= (1,input_length),\n",
    "                             padding=Parametres_layer[\"padding\"], \n",
    "                             sr= Parametres_layer[\"sr\"], \n",
    "                             n_mels=Parametres_layer[\"n_mels\"],\n",
    "                             fmin=40.0, fmax=  Parametres_layer[\"sr\"] / 2, power_melgram=1.0,\n",
    "                             return_decibel_melgram=True, trainable_fb=False,\n",
    "                             trainable_kernel=False,\n",
    "                             name='mel_stft')\n",
    "  mel_layer.trainable = False\n",
    "  \n",
    "  return mel_layer\n",
    "\n",
    "# construire une couche BRNN \n",
    "\n",
    "def Build_Bidiractionnel_layer(Parametres_layer):\n",
    "\n",
    "  cell= Build_RNN_layer(Parametres_layer)\n",
    "  layer=L.Bidirectional(cell)\n",
    "\n",
    "  return  layer \n",
    "\n",
    "# contruit un réseau feedforward \n",
    "def Build_MLP_Character_Dist(Parametres_mlp_CharDist,decoder_combined_context,vocabulary_length):\n",
    "\n",
    "  output=decoder_combined_context\n",
    "  for parametre in Parametres_mlp_CharDist:\n",
    "    output = L.TimeDistributed(L.Dense(units=parametre[\"units\"], activation=parametre[\"activation\"]))(output) # equation (5) of the paper\n",
    "  output = L.TimeDistributed(L.Dense(vocabulary_length, activation=\"softmax\"))(output) # equation (6) of the paper\n",
    "\n",
    "  return output \n",
    "# contruit une couche RNN selon son type \n",
    "\n",
    "def Build_RNN_layer(Parametre_layer):\n",
    "\n",
    "  if Parametre_layer[\"type_cell\"]== \"LSTM\" : \n",
    "    cell=L.LSTM(units=Parametre_layer[\"units\"],\n",
    "    dropout=Parametre_layer[\"dropout\"],\n",
    "    recurrent_dropout=Parametre_layer[\"recurrent_dropout\"],\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    stateful=Parametre_layer[\"stateful\"] , unroll=Parametre_layer[\"unroll\"] )   \n",
    "  elif Parametre_layer[\"type_cell\"]==\"CuDNNGRU\": \n",
    "    cell=CuDNNGRU(units=Parametre_layer[\"units\"],\n",
    "    dropout=Parametre_layer[\"dropout\"],\n",
    "    recurrent_dropout=Parametre_layer[\"recurrent_dropout\"],\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    stateful=Parametre_layer[\"stateful\"] , unroll=Parametre_layer[\"unroll\"] )\n",
    "  elif Parametre_layer[\"type_cell\"]==\"GRU\": \n",
    "    cell=L.GRU(units=Parametre_layer[\"units\"],\n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    stateful=Parametre_layer[\"stateful\"]  )\n",
    "  else : #by default CuDNNLSTM \n",
    "    cell= CuDNNLSTM(units=Parametre_layer[\"units\"],\n",
    "    \n",
    "    return_sequences=True,\n",
    "    return_state=True,\n",
    "    stateful=Parametre_layer[\"stateful\"]  )\n",
    "\n",
    "  return cell  \n",
    "\n",
    "#contruit la couche d'attention selon le type \n",
    "\n",
    "def Build_Attention_layer(Parametre_layer , encoder ,decoder ) : \n",
    "  \n",
    "  if Parametre_layer[\"type_attention\"]== \"Luong\" : \n",
    "    # the luong's attention \n",
    "    attention = L.dot([decoder[0], encoder], axes=[2, 2])\n",
    "    attention = L.Activation('softmax')(attention)\n",
    "    context = L.dot([attention, encoder], axes=[2,1])\n",
    "    decoder_combined_context = K.concatenate([context, decoder[0]])\n",
    "  elif Parametre_layer[\"type_attention\"] == \"Luong_keras\" : \n",
    "        # the luong's attention \n",
    "    context_vector = L.Attention(use_scale=Parametre_layer[\"use_scale\"],\n",
    "                                 causal=Parametre_layer[\"use_self_attention\"], \n",
    "                                 dropout = Parametre_layer[\"dropout\"] \n",
    "                                 )([decoder[0],encoder])\n",
    "    decoder_combined_context = K.concatenate([context_vector, decoder[0]])\n",
    "  elif Parametre_layer[\"type_attention\"] == \"Bah_keras\" : \n",
    "        #we are going to use the AditiveAttention = bahd of keras \n",
    "    context_vector = L.AdditiveAttention(use_scale=Parametre_layer[\"use_scale\"],\n",
    "                                 causal=Parametre_layer[\"use_self_attention\"], \n",
    "                                 dropout = Parametre_layer[\"dropout\"] )([decoder[0],encoder])\n",
    "    decoder_combined_context = K.concatenate([context_vector, decoder[0]])\n",
    "  \n",
    "  return decoder_combined_context \n",
    "\n",
    "# construit le CNN \n",
    "\n",
    "def BuildCNN(parametres_CNN,encoder ):\n",
    "\n",
    "  for para_CNN in parametres_CNN: \n",
    " \n",
    "    encoder = L.Conv2D(para_CNN[\"filters\"], para_CNN[\"kernel_size\"], activation=para_CNN[\"activation\"], padding='same')(encoder)\n",
    "    encoder = L.BatchNormalization()(encoder)\n",
    "    encoder=L.MaxPooling2D(para_CNN[\"kernel_size\"], strides=(2,2), padding='same')(encoder)\n",
    " \n",
    "  return encoder\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construire le modèle LAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Listen(input_length,parametres_melspectgtom,parametres_CNN,parametres_BRNN ) : \n",
    "    '''\n",
    "    parametres_melspectgtom : parametre de la couche Melspectrogram si length = 0 donc les audios sont déja mfcc\n",
    "    parametres_BRNN : a list that contains the parameters of the cells  for each bidectionnel layer \n",
    "    then  number_layers is the len of this list parametres_BRNN \n",
    "    parametres_CNN: parametres used to build the CNN network after the inputs \n",
    "    input_length is the len of the input audios \n",
    "    '''\n",
    "    number_layers = len(parametres_BRNN) \n",
    "    encoder_inputs = L.Input(shape=(input_length,))\n",
    "    \n",
    "    if parametres_melspectgtom[\"mfccs\"]==False  : \n",
    "        #MELSPECTROGRAM Layer \n",
    "        encoder_inputs = L.Input(shape=(input_length,))\n",
    "        encoder = L.Reshape((1, -1))(encoder_inputs)   \n",
    "        m=Build_MelSpectrogram(parametres_melspectgtom,input_length)\n",
    "        encoder = m(encoder)\n",
    "        encoder = Normalization2D( name='mel_stft_norm',str_axis='freq')(encoder)\n",
    "        # note that Melspectrogram puts the sequence in shape (batch_size, melDim, timeSteps, 1)\n",
    "        # we would rather have it the other way around for LSTMs (batch_size,timeSteps,melDim,1)\n",
    "        encoder = L.Permute((2, 1, 3))(encoder)\n",
    "        encoder = BuildCNN(parametres_CNN,encoder)\n",
    "        encoder = L.Lambda(lambda q: K.squeeze(q, -1), name='squeeze_last_dim')(encoder)\n",
    "        \n",
    "        \n",
    "    else :\n",
    "      encoder_inputs = L.Input(shape=(517,13,1))\n",
    "      encoder = BuildCNN(parametres_CNN,encoder_inputs)\n",
    "      encoder = L.Lambda(lambda q: K.squeeze(q, -1), name='squeeze_last_dim')(encoder)\n",
    "\n",
    "      #dans le cas ou nous avons des mfcc  \n",
    "    inputs=encoder\n",
    "    \n",
    "    encoder_state_fbw=None \n",
    "    for parametre in parametres_BRNN: \n",
    "        print(parametre)\n",
    "        bltsm_layer = Build_Bidiractionnel_layer(parametre)\n",
    "        encoder_outputs, forward_h, forward_c, backward_h, backward_c = bltsm_layer(inputs,initial_state=encoder_state_fbw)\n",
    "        state_h = L.Concatenate()([forward_h, backward_h])\n",
    "        state_c = L.Concatenate()([forward_c, backward_c])\n",
    "        encoder_state_fbw = [forward_h, backward_h,forward_c, backward_c]\n",
    "        inputs = L.Dropout(0.1)(encoder_outputs)\n",
    "        print(\"end\")\n",
    "    \n",
    "    #encoder_state = tuple(encoder_state_fbw * number_layers )\n",
    "    print(\"shape of encoder_outupts \" , encoder_outputs.shape)\n",
    "    print(\"shape of encode_states  \" , state_h.shape, state_c.shape)\n",
    "    \n",
    "    return  encoder_inputs,encoder_outputs,encoder_state_fbw\n",
    "    \n",
    "def AttendAndSpell(encoder,encoder_state_fbw ,output_length,vocabulary_length, parametres_rnns  , parametres_attention \n",
    "                   , dim_embedding  ,Parametres_mlp_CharDist   ): \n",
    "    \n",
    "    '''\n",
    "    encoder= encoder outputs \n",
    "    encoder_state_fbw : inputs of the decoder \n",
    "    parametres_rnns : parameters used to build the BRNN \n",
    "    output_length = length max of sentence ( output shape=150 )\n",
    "    parametres_attention = parameters  that discribe the attention layer   \n",
    "         available types : \n",
    "         Luong : luong costume layer \n",
    "         Luong_keras : luong of keras \"attention\" \n",
    "         Bah_keras : bahdanau attention implemented by keras \n",
    "    vocabulary_length: size of the vocabulary (50)\n",
    "    dim_embedding : dimention of the embedding \n",
    "    Parametres_mlp_CharDist: parameters to build the character distribution mlp\n",
    "    '''\n",
    "    decoder_inputs = L.Input(shape=(output_length,), name='decoder_inputs')\n",
    "    decoder_embedding = L.Embedding(vocabulary_length, dim_embedding ,input_length= output_length , name='decoder_embedding')(decoder_inputs)\n",
    "     #the RNN => si = RNN(si−1, yi−1, ci−1)\n",
    "    print(decoder_inputs.shape)\n",
    "    if len(parametres_rnns)!=0 : \n",
    "        state_h=K.concatenate([encoder_state_fbw[0], encoder_state_fbw[1]])\n",
    "        state_c=K.concatenate([encoder_state_fbw[2], encoder_state_fbw[3]])\n",
    "        initial_sta = [state_h,state_c]\n",
    "        #first layer with initial state = encoder_states \n",
    "        print(\"jaz 1\")\n",
    "        print(parametres_rnns)\n",
    "        decoder = Build_RNN_layer(parametres_rnns[0])(decoder_embedding,initial_state = initial_sta)\n",
    "        print(\"jaz 2\")\n",
    "        decoder_embedding = decoder \n",
    "      # stacked LSTMs with same number of units \n",
    "        for param in parametres_rnns[1:]:\n",
    "          decoder = Build_RNN_layer(param) (decoder_embedding)\n",
    "          decoder_embedding = decoder \n",
    "    else : \n",
    "      print(\"problem  ! \")\n",
    "    #construct of teh attention \n",
    "    decoder_combined_context = Build_Attention_layer(parametres_attention,encoder,decoder)\n",
    "  #the character distribution layer   \n",
    "    output=Build_MLP_Character_Dist(Parametres_mlp_CharDist,decoder_combined_context,vocabulary_length)\n",
    "    '''output = L.TimeDistributed(L.Dense(128, activation=\"tanh\"))(decoder_combined_context) # equation (5) of the paper\n",
    "    output = L.TimeDistributed(L.Dense(vocabulary_length, activation=\"softmax\"))(output) # equation (6) of the paper\n",
    "    '''\n",
    "    return output,decoder_inputs \n",
    "\n",
    "def build_model(NAME,input_length,output_length,vocabulary_length, parametre_mel,par_CNN, parametres_brnn  ,dim,\n",
    "                parametres_dec_rnns , parametres_attention,param_mlp_char_dist ) : \n",
    "    \n",
    "    encoder_inputs,encoder,encoder_state = Listen(input_length,parametre_mel,par_CNN, parametres_brnn ) \n",
    "    probabilities,decoder_inputs = AttendAndSpell(encoder,encoder_state ,output_length,vocabulary_length,\n",
    "                                                  parametres_dec_rnns \n",
    "                                                   , parametres_attention \n",
    "                                                  , dim  ,param_mlp_char_dist)\n",
    "    \n",
    "    model = Model(inputs=[encoder_inputs,decoder_inputs ] , outputs=[probabilities], name=NAME   )\n",
    "    model.summary()\n",
    "    with open('/content/drive/My Drive/Colab Notebooks/SpeechRecognition/archis_fitted_models/modelsummary{}.txt'.format(NAME), 'w') as f:\n",
    "      with redirect_stdout(f):\n",
    "        model.summary()\n",
    "    plot_model(model, to_file='/content/drive/My Drive/Colab Notebooks/SpeechRecognition/archis_fitted_models/{}_graph.png'.format(NAME))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#les paramétres fixer \n",
    "\n",
    "def Parametres (SabOuWidad=\"widad\") :\n",
    "  #encoder params\n",
    "\n",
    "  if  SabOuWidad==\"widad\" : \n",
    "    parametre_mel=[{\n",
    "              \"mfccs\" :  True , \n",
    "              \"n_dft\": 1024 , \n",
    "              \"n_hop\" :  128, \n",
    "             \n",
    "              \"padding\" :'same' , \n",
    "              \"sr\" : 22050 , \n",
    "            \"n_mels\" :80  , \n",
    "            } ]\n",
    "    parametres_CNN=[[\n",
    "                     { \"filters\" : 128 , \n",
    "                      \"kernel_size\" : (5,1), \n",
    "                      \"activation\" : 'relu'\n",
    "                         \n",
    "                     }, \n",
    "                      { \"filters\" : 64 , \n",
    "                      \"kernel_size\" : (5,1), \n",
    "                      \"activation\" : 'relu'\n",
    "                         \n",
    "                     }, \n",
    "                     {\n",
    "                         \"filters\" : 1 , \n",
    "                      \"kernel_size\" : (5,1), \n",
    "                      \"activation\" : 'relu'\n",
    "                     }\n",
    "                    ]\n",
    "                    ]\n",
    "                    \n",
    "    \n",
    "    parametres_brnn=[ [\n",
    "                      {\n",
    "                      \"type_cell\" : \"\" , \n",
    "                      \"units\": 32,  \n",
    "                      \"stateful\" : False  , \n",
    "                      \"recurrent_dropout\" : 0.0, \n",
    "                      \"dropout\"  : 0.1 , \n",
    "                      \"unroll\" : False  \n",
    "                      } , {\n",
    "                      \"type_cell\" : \"\" , \n",
    "                      \"units\": 32,  \n",
    "                      \"stateful\" : False  , \n",
    "                      \"recurrent_dropout\" : 0.0, \n",
    "                      \"dropout\"  : 0.1 , \n",
    "                      \"unroll\" : False  \n",
    "                      } \n",
    "                      \n",
    "      ]\n",
    "    ]\n",
    "\n",
    "\n",
    "    #decoder params \n",
    "    parametres_attention=[ \n",
    "    {\n",
    "        \"type_attention\" : \"Bah_keras\" , \n",
    "        \"use_scale\": False , \n",
    "        \"use_self_attention\" : True  , \n",
    "        \"dropout\" : 0.0\n",
    "    }  \n",
    "     ]\n",
    "    parametres_dec_rnns = [\n",
    "                      [\n",
    "                      {\n",
    "                      \"type_cell\" : \"\" , \n",
    "                      \"units\": 64, \n",
    "                      \"stateful\" : False  , \n",
    "                      \"unroll\" : False   , \n",
    "                      \"recurrent_dropout\" : 0.0, \n",
    "                      \"dropout\"  : 0.1 \n",
    "                      } , {\n",
    "                      \"type_cell\" : \"\" , \n",
    "                      \"units\": 64, \n",
    "                      \"stateful\" : False  , \n",
    "                      \"unroll\" : False   , \n",
    "                      \"recurrent_dropout\" : 0.0, \n",
    "                      \"dropout\"  : 0.1 \n",
    "                      }\n",
    "                      ] ]\n",
    "    parametres_mlp_CharDist =[\n",
    "                              [\n",
    "                               { \"units\" : 64 , \n",
    "                                \"activation\": \"tanh\"\n",
    "                                   \n",
    "                               },\n",
    "                               { \"units\" : 64 , \n",
    "                                \"activation\": \"tanh\"\n",
    "                                   \n",
    "                               }\n",
    "                              ]\n",
    "                            ]\n",
    "    dims_embedding=[200]\n",
    "    parametres_compil=[\n",
    "                    {\n",
    "        \"default\": True , \n",
    "        \"name_opt\" : \"nadam\" , \n",
    "        \"decay\" : 0.95, \n",
    "        \"lr\" :  0.05\n",
    "    } \n",
    "    ]\n",
    "    parametres_fit = [{\n",
    "        \"epochs\" : 1000 , \n",
    "        \"batch_size\": 32 , \n",
    "        \"cross_validation\" : True , \n",
    "        \"type_cross_validation\" : \"KFold\" , \n",
    "        \"n_splits\" : 4 , \n",
    "        \"shuffle\" : True , \n",
    "        \"random_state\": 42 , \n",
    "        \"initial_epoch\" : 0, \n",
    "        \n",
    "    }]\n",
    "\n",
    "                \n",
    "\n",
    "   \n",
    "  return parametre_mel,parametres_CNN,parametres_brnn,dims_embedding,parametres_attention, parametres_dec_rnns,parametres_mlp_CharDist, parametres_compil , parametres_fit   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cette fonction compile le modéle en précisant l 'optimiseur avec ses paramétres \n",
    "\n",
    "def compileModel(model,parametres_compil): \n",
    "\n",
    "  if parametres_compil[\"default\"]  == True : \n",
    "        opt=parametres_compil[\"name_opt\"] \n",
    "  else : \n",
    "    if parametres_compil[\"name_opt\"] ==\"rmsprop\" : \n",
    "      opt = tf.keras.optimizers.RMSprop(\n",
    "              learning_rate=parametres_compil[\"lr\"],\n",
    "              rho=parametres_compil[\"decay\"],\n",
    "              momentum=parametres_compil[\"momentum\"],\n",
    "              epsilon=1e-07,\n",
    "              centered=False   \n",
    "            )\n",
    "    elif parametres_compil[\"name_opt\"] ==\"adam\" : \n",
    "      \n",
    "      opt=  tf.keras.optimizers.Adam(\n",
    "        learning_rate=parametres_compil[\"lr\"],\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-07,\n",
    "        amsgrad=False \n",
    "      )\n",
    "    elif parametres_compil[\"name_opt\"] ==\"adadelta\" : \n",
    "      opt = tf.keras.optimizers.Adadelta(\n",
    "          learning_rate=parametres_compil[\"lr\"], rho=parametres_compil[\"decay\"], epsilon=1e-6\n",
    "        )\n",
    "    elif parametres_compil[\"name_opt\"] ==\"adamax\" : \n",
    "      opt=  tf.keras.optimizers.Adamax(\n",
    "        learning_rate=parametres_compil[\"lr\"], beta_1=0.9, beta_2=0.999, epsilon=1e-07\n",
    "        )\n",
    "    elif parametres_compil[\"name_opt\"] ==\"nadam\" : \n",
    "      \n",
    "      opt= tf.keras.optimizers.Nadam(\n",
    "          learning_rate= parametres_compil[\"lr\"], beta_1=0.9, beta_2=0.999, epsilon=1e-07     \n",
    "          )\n",
    "    elif parametres_compil[\"name_opt\"] ==\"sgd\" : \n",
    "     \n",
    "      opt = tf.keras.optimizers.SGD(\n",
    "             learning_rate= parametres_compil[\"lr\"], momentum=parametres_compil[\"lr\"], nesterov=False \n",
    "          )\n",
    "    \n",
    "  model.compile(optimizer=opt, loss=['categorical_crossentropy'], metrics=[tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\", dtype=None)])\n",
    "\n",
    "  return model \n",
    "\n",
    "# défintion des callbaks : tensorboard , early stopper et reduce lr et le checkpointer \n",
    "\n",
    "def Callbacks(NAME): \n",
    "\n",
    "  earlystopper = EarlyStopping(monitor='val_loss', patience=10,verbose=1, restore_best_weights=True)\n",
    "  checkpointer = ModelCheckpoint('./checkpoints_models/model-checkpoint{}.h5'.format(NAME), monitor='val_loss',\n",
    "                         save_best_only=True, save_weights_only=False,\n",
    "                         mode='auto', save_freq='epoch', verbose=1)\n",
    "  callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1,\n",
    "                                       min_lr=1e-4,\n",
    "                                       patience=0,\n",
    "                                       verbose=1)\n",
    "  callback_tensorboard =TensorBoard(log_dir=\"/content/drive/My Drive/Colab Notebooks/SpeechRecognition/tensorboard_logs/{}\".format(NAME),\n",
    "                                   histogram_freq=1,\n",
    "                                   write_graph=True, profile_batch=0)\n",
    "  return  [earlystopper,checkpointer,callback_reduce_lr,callback_tensorboard]\n",
    "\n",
    "# evaluation du modéle \n",
    "def Evaluate_model(model,validation_encoder_input,validation_decoder_input,validation_decoder_output): \n",
    "    history = model.evaluate(\n",
    "    x=[validation_encoder_input, validation_decoder_input],\n",
    "    y=[validation_decoder_output] ) \n",
    "    return history \n",
    "#apprentissage et enregistrement du modéle \n",
    "\n",
    "def Fit_And_Save_And_Evaluate(model,NAME, parametres_fit, training_encoder_input\n",
    "                              , training_decoder_input\n",
    "                              ,training_decoder_output\n",
    "                              ,validation_encoder_input\n",
    "                              ,validation_decoder_input, validation_decoder_output): \n",
    "\n",
    "  print(training_encoder_input.shape)\n",
    "  print(training_decoder_input.shape)\n",
    "  print(training_decoder_output.shape)\n",
    "  results = model.fit(\n",
    "      x=[training_encoder_input, training_decoder_input],\n",
    "      y=[training_decoder_output],shuffle=True,\n",
    "      validation_data=([validation_encoder_input, validation_decoder_input], [validation_decoder_output]),\n",
    "      verbose=2,batch_size=parametres_fit[\"batch_size\"], callbacks=Callbacks(NAME)\n",
    "      , epochs=parametres_fit[\"epochs\"],initial_epoch=0)\n",
    "  evaluation_history=Evaluate_model(model,validation_encoder_input,validation_decoder_input,validation_decoder_output)\n",
    "  model.save('/content/drive/My Drive/Colab Notebooks/SpeechRecognition/fitted_moddels/{}_{}.h5'.format(NAME,evaluation_history))\n",
    "  \n",
    "  return model , results  , evaluation_history\n",
    "\n",
    "# apprentissage d'une configuration \n",
    "def One_step_main(path_csv,parametre_mel,par_CNN, parametres_brnn,dim,parametres_dec_rnns , \n",
    "                  parametres_attention ,param_mlp_char_dist, parametres_compil , parametres_fit): \n",
    "  df=pd.read_csv(path_csv,sep=\";\")\n",
    "  if parametres_fit[\"cross_validation\"] == False : \n",
    "    input_length,output_length,vocabulary_length,training_encoder_input, training_decoder_input,training_decoder_output,validation_encoder_input,validation_decoder_input, validation_decoder_output = Load_resempaled_data(shuffle=parametres_fit[\"shuffle\"] ,split=True,mfccs=parametre_mel[\"mfccs\"] )\n",
    "    NAME = \"Modele_SpeechReco_mfccs{}\".format(int(time.time()))  # a unique name for the model \n",
    "    print(\"building the model \", NAME)\n",
    "    #les parametres    \n",
    "    model=build_model(NAME,input_length,output_length,vocabulary_length, parametre_mel,par_CNN, parametres_brnn  ,dim,\n",
    "                  parametres_dec_rnns , parametres_attention,param_mlp_char_dist )\n",
    "    model =compileModel(model, parametres_compil )\n",
    "    model , results , evaluation_history = Fit_And_Save_And_Evaluate(model,NAME,parametres_fit\n",
    "                                                                     ,training_encoder_input\n",
    "                                                                     , training_decoder_input\n",
    "                                                                     ,training_decoder_output\n",
    "                                                                     ,validation_encoder_input\n",
    "                                                                     ,validation_decoder_input, validation_decoder_output)\n",
    "    df = Update_csv_params(df,NAME,evaluation_history,parametres_fit,parametres_compil , path_csv)\n",
    "    \n",
    "  else  : \n",
    "    # ici on execute la cross_validation \n",
    "    input_length,output_length,vocabulary_length,training_encoder_input, training_decoder_input,training_decoder_output= Load_resempaled_data(shuffle=parametres_fit[\"shuffle\"] ,split=False,mfccs=parametre_mel[\"mfccs\"] )\n",
    "\n",
    "    if parametres_fit[\"type_cross_validation\"] == \"KFold\": \n",
    "      kf = KFold(n_splits =  parametres_fit[\"n_splits\"] ,shuffle= parametres_fit[\"shuffle\"] \n",
    "                 , random_state=parametres_fit[\"random_state\"])\n",
    "\n",
    "    elif parametres_fit[\"type_cross_validation\"] == \"StratifiedKFold\": \n",
    "      kf = StratifiedKFold(n_splits =  parametres_fit[\"n_splits\"] ,shuffle= parametres_fit[\"shuffle\"] \n",
    "                 , random_state=parametres_fit[\"random_state\"])\n",
    "    i=0  \n",
    "    #print(\"aw ? \", training_encoder_input)\n",
    "    dataset_split=[]\n",
    "    for train_index, test_index in kf.split(training_encoder_input):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        train_index = train_index.astype(int)\n",
    "        test_index = test_index.astype(int)\n",
    "        X_encoder_train, X_encoder_test = training_encoder_input[train_index], training_encoder_input[test_index]\n",
    "        X_decoder_train, X_decoder_test = training_decoder_input[train_index], training_decoder_input[test_index]\n",
    "        y_train, y_test = training_decoder_output[train_index], training_decoder_output[test_index]\n",
    "        NAME = \"Modele_SpeechReco_{}\".format(int(time.time()))  # a unique name for the model \n",
    "        print(\"building the model \", NAME)\n",
    "        #les parametres    \n",
    "        model=build_model(NAME,input_length,output_length,vocabulary_length, parametre_mel,par_CNN, parametres_brnn  ,dim,\n",
    "                      parametres_dec_rnns , parametres_attention,param_mlp_char_dist )\n",
    "        model = compileModel(model, parametres_compil )\n",
    "        model , results , evaluation_history = Fit_And_Save_And_Evaluate(model,NAME,parametres_fit\n",
    "                                                                        ,X_encoder_train\n",
    "                                                                        , X_decoder_train\n",
    "                                                                        ,y_train\n",
    "                                                                        ,X_encoder_test\n",
    "                                                                        ,X_decoder_test, y_test)\n",
    "        \n",
    "        k_fold_set = {\n",
    "                    'k_fold': i,\n",
    "                    'train': {'X_1': X_encoder_train, 'X_2': X_decoder_train, 'Y': y_train},\n",
    "                    'test': {'X_1': X_encoder_test, 'X_2': X_decoder_test, 'Y': y_test}\n",
    "                    }\n",
    "        df = Update_csv_params(df,NAME,evaluation_history,parametres_fit,parametres_compil , path_csv)\n",
    "        dataset_split.append(k_fold_set)\n",
    "        i = i + 1\n",
    "\n",
    "# ici on modifie un csv qui contient les résultats avec paramétrage \n",
    "  \n",
    "def Update_csv_params(df , NAME, history , param_fit,param_compil, path_csv ) :\n",
    "    \n",
    "    line = {\"name_model\" : NAME , \n",
    "            \"val_loss\" : history[0], \n",
    "            \"val_acc\" : history[1] \n",
    "           }\n",
    "    line.update(param_fit)\n",
    "    line.update(param_compil)\n",
    "    #line=team = dict(param_fit.items() + team_b.items())\n",
    "    df_line = pd.DataFrame([line]) \n",
    "    df_appended = df.append(df_line, ignore_index = True)\n",
    "    df_appended.to_csv(path_csv,sep=\";\" )\n",
    "    \n",
    "    return df_appended \n",
    "    \n",
    "# Main globale     \n",
    "def MAIN(path_csv = \"/content/drive/My Drive/Colab Notebooks/SpeechRecognition/dict_logs.csv\") :\n",
    "\n",
    "  \n",
    "  parametre_mel,parametres_CNN,parametres_brnn,dims_embedding,parametres_attention, parametres_dec_rnns,parametres_mlp_CharDist, parametres_compil , parametres_fit  =  Parametres(SabOuWidad=\"widad\")\n",
    "  \n",
    "  for par_fit in parametres_fit: \n",
    "    for par_compil in parametres_compil  : \n",
    "      for par_mel in parametre_mel: \n",
    "        for par_CNN in parametres_CNN: \n",
    "          for par_brnn_enc in parametres_brnn :\n",
    "            for dim in  dims_embedding : \n",
    "              for par_att in parametres_attention : \n",
    "                for para_rnn_dec in parametres_dec_rnns: \n",
    "                  for param_mlp_char in parametres_mlp_CharDist :\n",
    "                    One_step_main(path_csv,par_mel,par_CNN,par_brnn_enc, dim, para_rnn_dec,par_att,param_mlp_char,par_compil,par_fit)\n",
    "                    print(\"END of the configuration \")\n",
    "                    #save results in the dataframe of parametres ! \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MAIN()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
